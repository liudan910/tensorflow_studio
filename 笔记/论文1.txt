一 Text understanding from scratch

目前为止，大多数机器学习方法都是将一串字符组成一个结构，例如单词，短语，句子和段落，然后将一些统计分类
算法应用到这些结构的统计上，但是prior知识是不便宜的，需要定义一个字典，一旦语言发生改变，就得重建。

常用的字级别特征提取：查找表lookup table和word2vec feed给时态卷积网络中。通过让卷积网络训练在结构化的预测任务中如演讲打标，命名的实体识别和文本理解任务如情感分类，句子分类。
声称有很好的效果，但是合适的数据集和模型相对较小，并且仍然有一些工程层来表示诸如单词、短语和句子之类。

本文展示了deep learning系统可以处理文本和句子，而不需要人为地嵌入与语言相关的词汇、知识、句子或其他句法或
语义结构的知识。将时间上的卷积应用于各种大规模的文本理解任务中。
设计及结构同论文2一模一样。

卷积模型：
将构造词库，然后将文本译成词库中索引序列作为训练数据
模型结构：
（卷积层                   提特征
  最大池化层）六组         属性不变性，减少参数
  全连接层
  dropout层  pro=0.5
  全连接层
  dropout层  pro=0.5       分类
  全连接层 ）
根据Frame即输入大小分为大卷积，小卷积

bag-of-words模型：对每个数据集，统计每个单词在训练集中出现的频率，并选择5000个最高频率的单词，使用单词统计作为特征。
                  然后使用多项LR作为这个袋子的分类器。
对于Word2vec模型，先在词向量上运行k-means来从Google新闻语料库中学习k-5000,然后使用中心词id进行逻辑项回归。

实例1:本体分类。
将数据集中文本分成14类：公司，教育机构，作家，公务员，建筑，动物，植物等
数据集来自众包社区从Wikipedia提取结构化信息的DPpedia
模型    同义词补充 训练效果 测试效果
大卷积模型：No      99.96%   98.27%
            Yes     99.89%   98.40%
小卷积模型：No      99.37%   98.02%
            Yes     99.62%   98.15%
Bag of Words No     96.29%   96.19%
word2vec     No     89.32%   89.09%
实例2：情感分析
识别和目标信息。
在呈现用户所写的文本时，这个任务可定义为一个分类问题。每个类别代表一个程度指示器或用户的主观评价。
如：Amazon的比分系统，从1到5个离散分数表示 用户对产品的主观评价。
实例：数据集来自SNAP（某项目）的审阅文本，包含600百万个用户对20000个产品的3000千万个评论，评分标签为5个等级。
完整数据集：
模型    同义词补充 训练效果 测试效果
大卷积模型：No      62.96%   58.69%
            Yes     68.90%   59.55%
小卷积模型：No      69.24%   59.47%
            Yes     62.11%   59.57%
Bag of Words No     54.45%   54.17%
word2vec     No     36.56%   36.50%
极性数据集
模型    同义词补充 训练效果 测试效果
大卷积模型：No      97.57%   94.49%
省略
同之前 效果排序： 大卷积 ，小卷积，Bag of words， word2vec

实例3：雅虎主题分类
人们在雅虎发布问题和答案。从这里获取 数据集。
构建一个主题分类数据集，类别数10： 社会&文化， 科学&数学，健康，教育&会议，计算机&互联网 娱乐&音乐，家庭与关系 政治&政府
将将问题的标题、内容、最好的答案内容拼接 ，然后将输入截断为1014长度，
一个大的模型一个epoch跑一天,小模型跑8小时。
效果：训练集与测试集的精度几乎一样即泛化误差很好，估计是因为某些类别有混淆， 因为给出两个疸和答案。
混淆矩阵：即将一个类别的预测成另一个类型的数量 。

同之前 效果排序： 大卷积 ，小卷积，Bag of words， word2vec
且有词典扩充优于没有词典扩充。
实例4： 英语中的新闻分类
四个类别：世界，体育，商业，科学/技术
实例5：中文的新闻分类

模型    同义词补充 训练效果 测试效果
大卷积模型：No      99.14%   95.12%
小卷积模型  No     93.95%   91.35%
Bag of Words  No    92.97%  92.78%


总结：使用CNN从零可以做文本理解，从零指不需要给定语义、语法结构的知识。
DL在不同领域或问题上都有很好的表现，特别 是图像识别 方面。
此外，可以考虑将无监督学习应用到从零开始学习的语言模型中。

自然语言本质上是一种伪装的时间序列，因此，本方法的一个自然扩展是时间序列数据。
本文只对它的语义或情感意义应用了总面积，另一个明显扩展是传统NLP任务，如分块，命名实体识别（NER),和部分语音标签。

论文结论：
1.使用同义词典的数据填充
适当的数据填充技术对于控制深度学习模型的泛化错误很有用。
当我们可以找到模型应该拥有的适当的不变属性时，这些技巧通常会很好地发挥作用。
如图像识别中，一个模型应该对输入图像的平移，缩放、旋转和释放有一定的控制不变性。
同样在语音识别时，我们通常通过增加人工噪音背景和改变语言信号的语调或速度。

就文本而言，用图像或语音识别中的信号转换来增加数据是不适合的，因为
字符的精确顺序 会形成严格的语法和语义意义。
因此，最好的增加数据是使用人的句子。但是这不现实的，代价昂贵。
对我们来说，最自然的选择是用它们的同义词替换单词或短语。
问题： 在文本中应该要替换哪些词，用什么词去替换。
答：从给定的文本中找出所有可替换的词，并随机地挑出r个替换，
数字r是一个几何分布参数P[r]= P的r次方
选择的同义词索引s由几何P[s]=q的s次方决定。
这样，当它远离常见的词义时，选择同义词概率就会变小。



























